{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ems/Projects/futuristic-stk/stk'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "\n",
    "    def __init__(self, filename, split, cols):\n",
    "        dataframe = pd.read_csv(filename)\n",
    "        i_split = int(len(dataframe) * split)\n",
    "        self.data_train = dataframe.get(cols).values[:i_split]\n",
    "        self.data_test  = dataframe.get(cols).values[i_split:]\n",
    "        self.len_train  = len(self.data_train)\n",
    "        self.len_test   = len(self.data_test)\n",
    "        self.len_train_windows = None\n",
    "\n",
    "    def get_train_data(self, seq_len, normalise):\n",
    "        data_x = []\n",
    "        data_y = []\n",
    "        for i in range(self.len_train - seq_len):\n",
    "            x, y = self._next_window(i, seq_len, normalise)\n",
    "            data_x.append(x)\n",
    "            data_y.append(y)\n",
    "        return np.array(data_x), np.array(data_y)\n",
    "\n",
    "    def normalise_windows(self, window_data, single_window=False):\n",
    "        '''Normalise window with a base value of zero'''\n",
    "        normalised_data = []\n",
    "        window_data = [window_data] if single_window else window_data\n",
    "        for window in window_data:\n",
    "            normalised_window = []\n",
    "            for col_i in range(window.shape[1]):\n",
    "                normalised_col = [((float(p) / float(window[0, col_i])) - 1) for p in window[:, col_i]]\n",
    "                normalised_window.append(normalised_col)\n",
    "                    # reshape and transpose array back into original multidimensional format\n",
    "            normalised_window = np.array(normalised_window).T                \n",
    "            normalised_data.append(normalised_window)\n",
    "        return np.array(normalised_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model():\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tself.model = Sequential()\n",
    "\n",
    "\tdef build_model(self, configs):\n",
    "\t\t#timer = Timer()\n",
    "\t\t#timer.start()\n",
    "\n",
    "\t\tfor layer in configs['model']['layers']:\n",
    "\t\t\tneurons = layer['neurons'] if 'neurons' in layer else None\n",
    "\t\t\tdropout_rate = layer['rate'] if 'rate' in layer else None\n",
    "\t\t\tactivation = layer['activation'] if 'activation' in layer else None\n",
    "\t\t\treturn_seq = layer['return_seq'] if 'return_seq' in layer else None\n",
    "\t\t\tinput_timesteps = layer['input_timesteps'] if 'input_timesteps' in layer else None\n",
    "\t\t\tinput_dim = layer['input_dim'] if 'input_dim' in layer else None\n",
    "\n",
    "\t\t\tif layer['type'] == 'dense':\n",
    "\t\t\t\tself.model.add(Dense(neurons, activation=activation))\n",
    "\t\t\tif layer['type'] == 'lstm':\n",
    "\t\t\t\tself.model.add(LSTM(neurons, input_shape=(input_timesteps, input_dim), return_sequences=return_seq))\n",
    "\t\t\tif layer['type'] == 'dropout':\n",
    "\t\t\t\tself.model.add(Dropout(dropout_rate))\n",
    "\n",
    "\t\tself.model.compile(loss=configs['model']['loss'], optimizer=configs['model']['optimizer'])\n",
    "\n",
    "\t\tprint('[Model] Model Compiled')\n",
    "\t\t#timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model] Model Compiled\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute '_next_window'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-74f669e39fb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m x, y = data.get_train_data(\n\u001b[1;32m     12\u001b[0m         \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence_length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mnormalise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'normalise'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-9bf78c98a745>\u001b[0m in \u001b[0;36mget_train_data\u001b[0;34m(self, seq_len, normalise)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdata_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mdata_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mdata_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute '_next_window'"
     ]
    }
   ],
   "source": [
    "configs = json.load(open('config.json', 'r'))\n",
    "\n",
    "data = DataLoader(\n",
    "\tos.path.join('data', configs['data']['filename']),\n",
    "\tconfigs['data']['train_test_split'],\n",
    "\tconfigs['data']['columns']\n",
    ")\n",
    "\n",
    "model = Model()\n",
    "model.build_model(configs)\n",
    "x, y = data.get_train_data(\n",
    "\tseq_len = configs['data']['sequence_length'],\n",
    "\tnormalise = configs['data']['normalise']\n",
    ")\n",
    "\n",
    "# out-of memory generative training\n",
    "steps_per_epoch = math.ceil((data.len_train - configs['data']['sequence_length']) / configs['training']['batch_size'])\n",
    "model.train_generator(\n",
    "\tdata_gen = data.generate_train_batch(\n",
    "\t\tseq_len = configs['data']['sequence_length'],\n",
    "\t\tbatch_size = configs['training']['batch_size'],\n",
    "\t\tnormalise = configs['data']['normalise']\n",
    "\t),\n",
    "\tepochs = configs['training']['epochs'],\n",
    "\tbatch_size = configs['training']['batch_size'],\n",
    "\tsteps_per_epoch = steps_per_epoch\n",
    ")\n",
    "\n",
    "x_test, y_test = data.get_test_data(\n",
    "\tseq_len = configs['data']['sequence_length'],\n",
    "\tnormalise = configs['data']['normalise']\n",
    ")\n",
    "\n",
    "predictions_multiseq = model.predict_sequences_multiple(x_test, configs['data']['sequence_length'], configs['data']['sequence_length'])\n",
    "predictions_fullseq = model.predict_sequence_full(x_test, configs['data']['sequence_length'])\n",
    "predictions_pointbypoint = model.predict_point_by_point(x_test)        \n",
    "\n",
    "plot_results_multiple(predictions_multiseq, y_test, configs['data']['sequence_length'])\n",
    "plot_results(predictions_fullseq, y_test)\n",
    "plot_results(predictions_pointbypoint, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "predictions_pointbypoint = model.predict_point_by_point(x_test)\n",
    "plot_results(predictions_pointbypoint, y_test)\n",
    "\n",
    "predictions_fullseq = model.predict_sequence_full(x_test, configs['data']['sequence_length'])\n",
    "plot_results(predictions_fullseq, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
